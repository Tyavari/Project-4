{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN-RealEstate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBVz6K3uHh43"
      },
      "source": [
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/Tyavari/Project-4/main/NYC_Sales_Clean.csv'\n",
        "df1 = pd.read_csv(url)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVeWO3OzInCR"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjbSMRaaIwbR",
        "outputId": "7ea93ba3-7c36-433d-fa81-1a2eee5cdc27"
      },
      "source": [
        "nyc_sales_df = (df1.drop(columns=['RESIDENTIAL UNITS', 'COMMERCIAL UNITS','BUILDING CLASS AT TIME OF SALE', 'LAND SQUARE FEET']))\n",
        "nyc_sales_df = nyc_sales_df.rename(columns={'GROSS SQUARE FEET': \"SQFT\"})\n",
        "nyc_sales_df = nyc_sales_df[nyc_sales_df.SQFT !=\" -  \"]\n",
        "nyc_sales_df[\"SQFT\"] = pd.to_numeric(nyc_sales_df[\"SQFT\"])\n",
        "print(nyc_sales_df.shape)\n",
        "print(nyc_sales_df['BUILDING CLASS CATEGORY'].unique())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(43353, 9)\n",
            "['07 RENTALS - WALKUP APARTMENTS             '\n",
            " '08 RENTALS - ELEVATOR APARTMENTS           '\n",
            " '09 COOPS - WALKUP APARTMENTS               '\n",
            " '11A CONDO-RENTALS                           '\n",
            " '14 RENTALS - 4-10 UNIT                     '\n",
            " '01 ONE FAMILY DWELLINGS                    '\n",
            " '02 TWO FAMILY DWELLINGS                    '\n",
            " '03 THREE FAMILY DWELLINGS                  '\n",
            " '17 CONDO COOPS                             '\n",
            " '10 COOPS - ELEVATOR APARTMENTS             '\n",
            " '12 CONDOS - WALKUP APARTMENTS              '\n",
            " '13 CONDOS - ELEVATOR APARTMENTS            '\n",
            " '46 CONDO STORE BUILDINGS                   '\n",
            " '15 CONDOS - 2-10 UNIT RESIDENTIAL          '\n",
            " '16 CONDOS - 2-10 UNIT WITH COMMERCIAL UNIT ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qTvVueUI85T",
        "outputId": "1a4aa656-20ac-44c7-9a7b-03555c0fced8"
      },
      "source": [
        "# prep One hot Encoding \n",
        "# print(nyc_sales_df['NEIGHBORHOOD'].nunique())\n",
        "# print(nyc_sales_df['BUILDING CLASS CATEGORY'].nunique())\n",
        "# print(nyc_sales_df['SALE PERIOD'].nunique())\n",
        "# KEEPNS = nyc_sales_df['NEIGHBORHOOD'].value_counts().sort_values(ascending=False).head(30)\n",
        "# for idx,row in nyc_sales_df.iterrows():\n",
        "#     t = row['NEIGHBORHOOD']\n",
        "#     if t in KEEPNS:\n",
        "#         pass\n",
        "#     else:\n",
        "#         #nyc_sales_df = nyc_sales_df.drop(index=idx, axis=0)\n",
        "#         #nyc_sales_df.loc[idx,'NEIGHBORHOOD'] = 'Other'\n",
        "#         nyc_sales_df = nyc_sales_df.drop(index=idx, axis=0)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247\n",
            "15\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ1MRt7JKDKv",
        "outputId": "9aaf87d9-8e80-4231-942c-fcd7d48acc3f"
      },
      "source": [
        "nyc_sales_df['NEIGHBORHOOD'].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BEDFORD STUYVESANT         1259\n",
              "BOROUGH PARK                989\n",
              "EAST NEW YORK               856\n",
              "SHEEPSHEAD BAY              826\n",
              "BAY RIDGE                   769\n",
              "                           ... \n",
              "FRESH KILLS                   1\n",
              "TRIBECA                       1\n",
              "CO-OP CITY                    1\n",
              "NEW BRIGHTON-ST. GEORGE       1\n",
              "ROOSEVELT ISLAND              1\n",
              "Name: NEIGHBORHOOD, Length: 247, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8aRZiKENQoy"
      },
      "source": [
        "df = pd.get_dummies(nyc_sales_df, drop_first=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j24OLSyNQXeP"
      },
      "source": [
        "# Separate features\n",
        "X = df.drop([\"SALE_PRICE\"], axis=1)\n",
        "y = df[\"SALE_PRICE\"]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYdPX48bQlne"
      },
      "source": [
        "\n",
        "train, test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBYV57qPQpg5"
      },
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(train)\n",
        "X_test_scaled = X_scaler.transform(test)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnaLLiTwQy82",
        "outputId": "c71ad9ca-abfd-4fd7-c2c4-ad150c846094"
      },
      "source": [
        "X_train_scaled.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14118, 58)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PKHHN3zQte_",
        "outputId": "c6724abb-43e9-43f8-e57f-825dd76ef519"
      },
      "source": [
        "nn_model = tf.keras.models.Sequential()\n",
        "\n",
        "# first hidden layer\n",
        "nn_model.add(tf.keras.layers.Dense(units=4, activation=\"tanh\", input_dim=58))\n",
        "\n",
        "# Second hidden layer\n",
        "# nn_model.add(tf.keras.layers.Dense(units=6, activation=\"tanh\"))\n",
        "\n",
        "# output layer \n",
        "nn_model.add(tf.keras.layers.Dense(units=3, activation=\"tanh\"))\n",
        "\n",
        "\n",
        "# Check the structure of the model\n",
        "nn_model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 4)                 236       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 3)                 15        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 251\n",
            "Trainable params: 251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ganyzioQ7A2"
      },
      "source": [
        "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM_PqjCdQ9KP",
        "outputId": "9c37f96a-e934-496e-92dd-571c871e468e"
      },
      "source": [
        "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=125)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 3476625.0000 - accuracy: 0.1225\n",
            "Epoch 2/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 1300387.1250 - accuracy: 0.1317\n",
            "Epoch 3/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -70811.5312 - accuracy: 0.1447\n",
            "Epoch 4/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -902397.6250 - accuracy: 0.1563\n",
            "Epoch 5/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -1782357.3750 - accuracy: 0.1606\n",
            "Epoch 6/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -2880305.5000 - accuracy: 0.1568\n",
            "Epoch 7/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -4031522.0000 - accuracy: 0.1398\n",
            "Epoch 8/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -5483348.5000 - accuracy: 0.1254\n",
            "Epoch 9/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -6947710.5000 - accuracy: 0.1102\n",
            "Epoch 10/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -8164820.0000 - accuracy: 0.1019\n",
            "Epoch 11/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -8543483.0000 - accuracy: 0.2063\n",
            "Epoch 12/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -8629369.0000 - accuracy: 0.2130\n",
            "Epoch 13/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -8712790.0000 - accuracy: 0.2130\n",
            "Epoch 14/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -8800674.0000 - accuracy: 0.2130\n",
            "Epoch 15/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -8893578.0000 - accuracy: 0.2130\n",
            "Epoch 16/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -8981304.0000 - accuracy: 0.2130\n",
            "Epoch 17/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9066211.0000 - accuracy: 0.2130\n",
            "Epoch 18/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9173195.0000 - accuracy: 0.2130\n",
            "Epoch 19/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9248884.0000 - accuracy: 0.2130\n",
            "Epoch 20/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9280428.0000 - accuracy: 0.2130\n",
            "Epoch 21/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9311922.0000 - accuracy: 0.2178\n",
            "Epoch 22/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9338918.0000 - accuracy: 0.2391\n",
            "Epoch 23/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9367456.0000 - accuracy: 0.2486\n",
            "Epoch 24/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9405665.0000 - accuracy: 0.2502\n",
            "Epoch 25/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9417219.0000 - accuracy: 0.2512\n",
            "Epoch 26/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9428250.0000 - accuracy: 0.2508\n",
            "Epoch 27/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9439284.0000 - accuracy: 0.2508\n",
            "Epoch 28/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9450171.0000 - accuracy: 0.2509\n",
            "Epoch 29/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9461191.0000 - accuracy: 0.2499\n",
            "Epoch 30/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9473092.0000 - accuracy: 0.2482\n",
            "Epoch 31/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9484015.0000 - accuracy: 0.2471\n",
            "Epoch 32/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9495353.0000 - accuracy: 0.2457\n",
            "Epoch 33/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9505972.0000 - accuracy: 0.2456\n",
            "Epoch 34/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9515844.0000 - accuracy: 0.2449\n",
            "Epoch 35/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9524364.0000 - accuracy: 0.2433\n",
            "Epoch 36/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9533076.0000 - accuracy: 0.2443\n",
            "Epoch 37/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9631179.0000 - accuracy: 0.2466\n",
            "Epoch 38/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9787604.0000 - accuracy: 0.2509\n",
            "Epoch 39/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9803223.0000 - accuracy: 0.2512\n",
            "Epoch 40/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9815653.0000 - accuracy: 0.2511\n",
            "Epoch 41/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9822762.0000 - accuracy: 0.2511\n",
            "Epoch 42/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9826262.0000 - accuracy: 0.2511\n",
            "Epoch 43/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9828763.0000 - accuracy: 0.2511\n",
            "Epoch 44/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9833385.0000 - accuracy: 0.2509\n",
            "Epoch 45/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9792474.0000 - accuracy: 0.2510\n",
            "Epoch 46/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9835998.0000 - accuracy: 0.2512\n",
            "Epoch 47/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9836096.0000 - accuracy: 0.2512\n",
            "Epoch 48/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9836180.0000 - accuracy: 0.2512\n",
            "Epoch 49/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9836274.0000 - accuracy: 0.2511\n",
            "Epoch 50/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9836346.0000 - accuracy: 0.2509\n",
            "Epoch 51/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9836431.0000 - accuracy: 0.2510\n",
            "Epoch 52/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9836520.0000 - accuracy: 0.2510\n",
            "Epoch 53/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9836681.0000 - accuracy: 0.2512\n",
            "Epoch 54/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9836785.0000 - accuracy: 0.2511\n",
            "Epoch 55/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9836941.0000 - accuracy: 0.2507\n",
            "Epoch 56/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9837134.0000 - accuracy: 0.2510\n",
            "Epoch 57/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9837266.0000 - accuracy: 0.2505\n",
            "Epoch 58/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9837458.0000 - accuracy: 0.2510\n",
            "Epoch 59/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9837601.0000 - accuracy: 0.2507\n",
            "Epoch 60/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9837792.0000 - accuracy: 0.2510\n",
            "Epoch 61/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9837961.0000 - accuracy: 0.2509\n",
            "Epoch 62/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9838151.0000 - accuracy: 0.2510\n",
            "Epoch 63/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9838376.0000 - accuracy: 0.2510\n",
            "Epoch 64/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9838525.0000 - accuracy: 0.2510\n",
            "Epoch 65/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9838662.0000 - accuracy: 0.2511\n",
            "Epoch 66/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9838811.0000 - accuracy: 0.2511\n",
            "Epoch 67/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9838932.0000 - accuracy: 0.2511\n",
            "Epoch 68/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9839068.0000 - accuracy: 0.2511\n",
            "Epoch 69/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9839247.0000 - accuracy: 0.2511\n",
            "Epoch 70/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9839379.0000 - accuracy: 0.2511\n",
            "Epoch 71/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9839459.0000 - accuracy: 0.2510\n",
            "Epoch 72/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9839691.0000 - accuracy: 0.2510\n",
            "Epoch 73/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9839827.0000 - accuracy: 0.2510\n",
            "Epoch 74/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9839967.0000 - accuracy: 0.2511\n",
            "Epoch 75/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9840131.0000 - accuracy: 0.2510\n",
            "Epoch 76/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9840268.0000 - accuracy: 0.2511\n",
            "Epoch 77/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9840408.0000 - accuracy: 0.2511\n",
            "Epoch 78/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9840576.0000 - accuracy: 0.2511\n",
            "Epoch 79/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9840691.0000 - accuracy: 0.2511\n",
            "Epoch 80/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9840867.0000 - accuracy: 0.2511\n",
            "Epoch 81/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9841019.0000 - accuracy: 0.2511\n",
            "Epoch 82/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9841181.0000 - accuracy: 0.2511\n",
            "Epoch 83/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9841367.0000 - accuracy: 0.2511\n",
            "Epoch 84/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9841504.0000 - accuracy: 0.2511\n",
            "Epoch 85/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9841648.0000 - accuracy: 0.2511\n",
            "Epoch 86/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9841780.0000 - accuracy: 0.2511\n",
            "Epoch 87/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9841906.0000 - accuracy: 0.2511\n",
            "Epoch 88/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9842087.0000 - accuracy: 0.2511\n",
            "Epoch 89/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9842186.0000 - accuracy: 0.2511\n",
            "Epoch 90/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9842284.0000 - accuracy: 0.2511\n",
            "Epoch 91/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9842416.0000 - accuracy: 0.2511\n",
            "Epoch 92/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9842552.0000 - accuracy: 0.2511\n",
            "Epoch 93/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9842639.0000 - accuracy: 0.2511\n",
            "Epoch 94/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9842756.0000 - accuracy: 0.2511\n",
            "Epoch 95/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9842864.0000 - accuracy: 0.2512\n",
            "Epoch 96/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9842988.0000 - accuracy: 0.2512\n",
            "Epoch 97/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843109.0000 - accuracy: 0.2512\n",
            "Epoch 98/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843195.0000 - accuracy: 0.2512\n",
            "Epoch 99/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843290.0000 - accuracy: 0.2512\n",
            "Epoch 100/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843355.0000 - accuracy: 0.2512\n",
            "Epoch 101/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843406.0000 - accuracy: 0.2512\n",
            "Epoch 102/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843536.0000 - accuracy: 0.2512\n",
            "Epoch 103/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843584.0000 - accuracy: 0.2512\n",
            "Epoch 104/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843666.0000 - accuracy: 0.2512\n",
            "Epoch 105/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843769.0000 - accuracy: 0.2512\n",
            "Epoch 106/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843819.0000 - accuracy: 0.2512\n",
            "Epoch 107/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843820.0000 - accuracy: 0.2512\n",
            "Epoch 108/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843819.0000 - accuracy: 0.2512\n",
            "Epoch 109/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843820.0000 - accuracy: 0.2512\n",
            "Epoch 110/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843819.0000 - accuracy: 0.2512\n",
            "Epoch 111/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843824.0000 - accuracy: 0.2512\n",
            "Epoch 112/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843825.0000 - accuracy: 0.2512\n",
            "Epoch 113/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843820.0000 - accuracy: 0.2512\n",
            "Epoch 114/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843820.0000 - accuracy: 0.2512\n",
            "Epoch 115/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843819.0000 - accuracy: 0.2512\n",
            "Epoch 116/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843818.0000 - accuracy: 0.2512\n",
            "Epoch 117/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843820.0000 - accuracy: 0.2512\n",
            "Epoch 118/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843820.0000 - accuracy: 0.2512\n",
            "Epoch 119/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843819.0000 - accuracy: 0.2512\n",
            "Epoch 120/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843821.0000 - accuracy: 0.2512\n",
            "Epoch 121/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843819.0000 - accuracy: 0.2512\n",
            "Epoch 122/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843820.0000 - accuracy: 0.2512\n",
            "Epoch 123/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843820.0000 - accuracy: 0.2512\n",
            "Epoch 124/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843818.0000 - accuracy: 0.2512\n",
            "Epoch 125/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: -9843825.0000 - accuracy: 0.2512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0bV465DUv1r"
      },
      "source": [
        "nn_model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHh6aqYsU8Ws",
        "outputId": "8eface86-4b51-4e5b-b45c-3041f37518a8"
      },
      "source": [
        "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=125)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 2/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452058112.0000 - accuracy: 0.2512\n",
            "Epoch 3/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 4/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452320256.0000 - accuracy: 0.2512\n",
            "Epoch 5/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453630976.0000 - accuracy: 0.2512\n",
            "Epoch 6/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452058112.0000 - accuracy: 0.2512\n",
            "Epoch 7/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730454679552.0000 - accuracy: 0.2512\n",
            "Epoch 8/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730451271680.0000 - accuracy: 0.2512\n",
            "Epoch 9/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730451009536.0000 - accuracy: 0.2512\n",
            "Epoch 10/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452058112.0000 - accuracy: 0.2512\n",
            "Epoch 11/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 12/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 13/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 14/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 15/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 16/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730451795968.0000 - accuracy: 0.2512\n",
            "Epoch 17/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453630976.0000 - accuracy: 0.2512\n",
            "Epoch 18/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 19/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 20/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 21/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453893120.0000 - accuracy: 0.2512\n",
            "Epoch 22/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 23/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 24/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453630976.0000 - accuracy: 0.2512\n",
            "Epoch 25/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 26/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 27/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452058112.0000 - accuracy: 0.2512\n",
            "Epoch 28/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 29/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730454941696.0000 - accuracy: 0.2512\n",
            "Epoch 30/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730451271680.0000 - accuracy: 0.2512\n",
            "Epoch 31/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730455728128.0000 - accuracy: 0.2512\n",
            "Epoch 32/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 33/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453630976.0000 - accuracy: 0.2512\n",
            "Epoch 34/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730454155264.0000 - accuracy: 0.2512\n",
            "Epoch 35/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730454155264.0000 - accuracy: 0.2512\n",
            "Epoch 36/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453630976.0000 - accuracy: 0.2512\n",
            "Epoch 37/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730454155264.0000 - accuracy: 0.2512\n",
            "Epoch 38/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 39/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730454155264.0000 - accuracy: 0.2512\n",
            "Epoch 40/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 41/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 42/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 43/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453630976.0000 - accuracy: 0.2512\n",
            "Epoch 44/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 45/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 46/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 47/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 48/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 49/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453630976.0000 - accuracy: 0.2512\n",
            "Epoch 50/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 51/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452320256.0000 - accuracy: 0.2512\n",
            "Epoch 52/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453630976.0000 - accuracy: 0.2512\n",
            "Epoch 53/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 54/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730451795968.0000 - accuracy: 0.2512\n",
            "Epoch 55/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452320256.0000 - accuracy: 0.2512\n",
            "Epoch 56/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 57/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730451271680.0000 - accuracy: 0.2512\n",
            "Epoch 58/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453893120.0000 - accuracy: 0.2512\n",
            "Epoch 59/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 60/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 61/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 62/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453630976.0000 - accuracy: 0.2512\n",
            "Epoch 63/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730454155264.0000 - accuracy: 0.2512\n",
            "Epoch 64/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452058112.0000 - accuracy: 0.2512\n",
            "Epoch 65/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452058112.0000 - accuracy: 0.2512\n",
            "Epoch 66/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 67/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452058112.0000 - accuracy: 0.2512\n",
            "Epoch 68/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 69/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 70/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 71/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730451795968.0000 - accuracy: 0.2512\n",
            "Epoch 72/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730454155264.0000 - accuracy: 0.2512\n",
            "Epoch 73/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452058112.0000 - accuracy: 0.2512\n",
            "Epoch 74/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 75/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730454679552.0000 - accuracy: 0.2512\n",
            "Epoch 76/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 77/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 78/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 79/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453893120.0000 - accuracy: 0.2512\n",
            "Epoch 80/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 81/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 82/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 83/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 84/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453893120.0000 - accuracy: 0.2512\n",
            "Epoch 85/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730454155264.0000 - accuracy: 0.2512\n",
            "Epoch 86/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 87/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 88/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 89/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730454155264.0000 - accuracy: 0.2512\n",
            "Epoch 90/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452320256.0000 - accuracy: 0.2512\n",
            "Epoch 91/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453630976.0000 - accuracy: 0.2512\n",
            "Epoch 92/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 93/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 94/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 95/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730451795968.0000 - accuracy: 0.2512\n",
            "Epoch 96/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 97/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452058112.0000 - accuracy: 0.2512\n",
            "Epoch 98/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 99/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452320256.0000 - accuracy: 0.2512\n",
            "Epoch 100/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453630976.0000 - accuracy: 0.2512\n",
            "Epoch 101/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 102/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 103/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453630976.0000 - accuracy: 0.2512\n",
            "Epoch 104/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453106688.0000 - accuracy: 0.2512\n",
            "Epoch 105/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730454155264.0000 - accuracy: 0.2512\n",
            "Epoch 106/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 107/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 108/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453630976.0000 - accuracy: 0.2512\n",
            "Epoch 109/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453630976.0000 - accuracy: 0.2512\n",
            "Epoch 110/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452320256.0000 - accuracy: 0.2512\n",
            "Epoch 111/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453630976.0000 - accuracy: 0.2512\n",
            "Epoch 112/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453893120.0000 - accuracy: 0.2512\n",
            "Epoch 113/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730454417408.0000 - accuracy: 0.2512\n",
            "Epoch 114/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 115/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453893120.0000 - accuracy: 0.2512\n",
            "Epoch 116/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452582400.0000 - accuracy: 0.2512\n",
            "Epoch 117/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 118/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452320256.0000 - accuracy: 0.2512\n",
            "Epoch 119/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452844544.0000 - accuracy: 0.2512\n",
            "Epoch 120/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730451795968.0000 - accuracy: 0.2512\n",
            "Epoch 121/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452320256.0000 - accuracy: 0.2512\n",
            "Epoch 122/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730454155264.0000 - accuracy: 0.2512\n",
            "Epoch 123/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730451795968.0000 - accuracy: 0.2512\n",
            "Epoch 124/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730453893120.0000 - accuracy: 0.2512\n",
            "Epoch 125/125\n",
            "442/442 [==============================] - 1s 2ms/step - loss: 2730452058112.0000 - accuracy: 0.2512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiVi5hC7Vxd8",
        "outputId": "5ab433a6-3a1c-4a0c-d693-da5cf9de476c"
      },
      "source": [
        "nn_model = tf.keras.models.Sequential()\n",
        "\n",
        "# first hidden layer\n",
        "nn_model.add(tf.keras.layers.Dense(units=10, activation=\"tanh\", input_dim=276))\n",
        "\n",
        "# Second hidden layer\n",
        "#nn_model.add(tf.keras.layers.Dense(units=3, activation=\"tanh\"))\n",
        "#nn_model.add(tf.keras.layers.Dense(units=6, activation=\"tanh\"))\n",
        "# output layer \n",
        "nn_model.add(tf.keras.layers.Dense(units=10, activation=\"tanh\"))\n",
        "\n",
        "\n",
        "# Check the structure of the model\n",
        "nn_model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 10)                2770      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,880\n",
            "Trainable params: 2,880\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4TLUn-bV5qr"
      },
      "source": [
        "nn_model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JR59NIMXV86A",
        "outputId": "f0035f76-d80c-47e1-a7c1-8b61c563888d"
      },
      "source": [
        "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=400)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "1084/1084 [==============================] - 2s 1ms/step - loss: 22340761026560.0000 - accuracy: 0.0494\n",
            "Epoch 2/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.0234\n",
            "Epoch 3/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340740055040.0000 - accuracy: 0.0128\n",
            "Epoch 4/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340721180672.0000 - accuracy: 0.0103\n",
            "Epoch 5/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.0104\n",
            "Epoch 6/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.0123\n",
            "Epoch 7/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340725374976.0000 - accuracy: 0.0139\n",
            "Epoch 8/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340723277824.0000 - accuracy: 0.0159\n",
            "Epoch 9/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.0330\n",
            "Epoch 10/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.0299\n",
            "Epoch 11/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340767318016.0000 - accuracy: 0.0709\n",
            "Epoch 12/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340712792064.0000 - accuracy: 0.0896\n",
            "Epoch 13/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.0798\n",
            "Epoch 14/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340721180672.0000 - accuracy: 0.0665\n",
            "Epoch 15/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.0643\n",
            "Epoch 16/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.0517\n",
            "Epoch 17/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.0472\n",
            "Epoch 18/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.0418\n",
            "Epoch 19/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340740055040.0000 - accuracy: 0.0355\n",
            "Epoch 20/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340771512320.0000 - accuracy: 0.0254\n",
            "Epoch 21/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.0230\n",
            "Epoch 22/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340756832256.0000 - accuracy: 0.0185\n",
            "Epoch 23/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340756832256.0000 - accuracy: 0.0183\n",
            "Epoch 24/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.0130\n",
            "Epoch 25/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340727472128.0000 - accuracy: 0.0106\n",
            "Epoch 26/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.0086\n",
            "Epoch 27/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340725374976.0000 - accuracy: 0.0081\n",
            "Epoch 28/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.0080\n",
            "Epoch 29/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.0118\n",
            "Epoch 30/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340788289536.0000 - accuracy: 0.0230\n",
            "Epoch 31/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.0213\n",
            "Epoch 32/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.0489\n",
            "Epoch 33/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340765220864.0000 - accuracy: 0.1061\n",
            "Epoch 34/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1201\n",
            "Epoch 35/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1268\n",
            "Epoch 36/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340765220864.0000 - accuracy: 0.1317\n",
            "Epoch 37/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1489\n",
            "Epoch 38/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1550\n",
            "Epoch 39/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1567\n",
            "Epoch 40/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340773609472.0000 - accuracy: 0.1606\n",
            "Epoch 41/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1650\n",
            "Epoch 42/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1717\n",
            "Epoch 43/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.1761\n",
            "Epoch 44/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.1818\n",
            "Epoch 45/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1847\n",
            "Epoch 46/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1850\n",
            "Epoch 47/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.1860\n",
            "Epoch 48/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340773609472.0000 - accuracy: 0.1868\n",
            "Epoch 49/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1868\n",
            "Epoch 50/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340733763584.0000 - accuracy: 0.1870\n",
            "Epoch 51/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1870\n",
            "Epoch 52/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340765220864.0000 - accuracy: 0.1874\n",
            "Epoch 53/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.1874\n",
            "Epoch 54/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340723277824.0000 - accuracy: 0.1875\n",
            "Epoch 55/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1876\n",
            "Epoch 56/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340740055040.0000 - accuracy: 0.1876\n",
            "Epoch 57/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1875\n",
            "Epoch 58/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1876\n",
            "Epoch 59/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340767318016.0000 - accuracy: 0.1875\n",
            "Epoch 60/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1875\n",
            "Epoch 61/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1875\n",
            "Epoch 62/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1875\n",
            "Epoch 63/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1875\n",
            "Epoch 64/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340731666432.0000 - accuracy: 0.1875\n",
            "Epoch 65/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340716986368.0000 - accuracy: 0.1875\n",
            "Epoch 66/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1875\n",
            "Epoch 67/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340723277824.0000 - accuracy: 0.1875\n",
            "Epoch 68/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340765220864.0000 - accuracy: 0.1875\n",
            "Epoch 69/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340740055040.0000 - accuracy: 0.1875\n",
            "Epoch 70/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340731666432.0000 - accuracy: 0.1875\n",
            "Epoch 71/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1875\n",
            "Epoch 72/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1875\n",
            "Epoch 73/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1875\n",
            "Epoch 74/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1875\n",
            "Epoch 75/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340725374976.0000 - accuracy: 0.1875\n",
            "Epoch 76/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1875\n",
            "Epoch 77/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340767318016.0000 - accuracy: 0.1875\n",
            "Epoch 78/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1875\n",
            "Epoch 79/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340725374976.0000 - accuracy: 0.1875\n",
            "Epoch 80/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1875\n",
            "Epoch 81/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1875\n",
            "Epoch 82/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340731666432.0000 - accuracy: 0.1875\n",
            "Epoch 83/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340756832256.0000 - accuracy: 0.1875\n",
            "Epoch 84/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1875\n",
            "Epoch 85/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340727472128.0000 - accuracy: 0.1875\n",
            "Epoch 86/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1875\n",
            "Epoch 87/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1875\n",
            "Epoch 88/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1875\n",
            "Epoch 89/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1875\n",
            "Epoch 90/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1875\n",
            "Epoch 91/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1875\n",
            "Epoch 92/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1875\n",
            "Epoch 93/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1875\n",
            "Epoch 94/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1875\n",
            "Epoch 95/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1875\n",
            "Epoch 96/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340733763584.0000 - accuracy: 0.1875\n",
            "Epoch 97/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1875\n",
            "Epoch 98/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340733763584.0000 - accuracy: 0.1875\n",
            "Epoch 99/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1875\n",
            "Epoch 100/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1875\n",
            "Epoch 101/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340740055040.0000 - accuracy: 0.1875\n",
            "Epoch 102/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1875\n",
            "Epoch 103/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1875\n",
            "Epoch 104/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1875\n",
            "Epoch 105/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340775706624.0000 - accuracy: 0.1875\n",
            "Epoch 106/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1875\n",
            "Epoch 107/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340761026560.0000 - accuracy: 0.1875\n",
            "Epoch 108/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1875\n",
            "Epoch 109/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1875\n",
            "Epoch 110/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1875\n",
            "Epoch 111/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1875\n",
            "Epoch 112/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1875\n",
            "Epoch 113/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340727472128.0000 - accuracy: 0.1875\n",
            "Epoch 114/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1875\n",
            "Epoch 115/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1875\n",
            "Epoch 116/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340777803776.0000 - accuracy: 0.1875\n",
            "Epoch 117/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1875\n",
            "Epoch 118/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1875\n",
            "Epoch 119/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340733763584.0000 - accuracy: 0.1875\n",
            "Epoch 120/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340761026560.0000 - accuracy: 0.1875\n",
            "Epoch 121/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1875\n",
            "Epoch 122/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 123/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340740055040.0000 - accuracy: 0.1876\n",
            "Epoch 124/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340740055040.0000 - accuracy: 0.1876\n",
            "Epoch 125/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340710694912.0000 - accuracy: 0.1876\n",
            "Epoch 126/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 127/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 128/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1876\n",
            "Epoch 129/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 130/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340777803776.0000 - accuracy: 0.1876\n",
            "Epoch 131/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340761026560.0000 - accuracy: 0.1876\n",
            "Epoch 132/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1876\n",
            "Epoch 133/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 134/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340725374976.0000 - accuracy: 0.1876\n",
            "Epoch 135/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.1876\n",
            "Epoch 136/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 137/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1876\n",
            "Epoch 138/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1876\n",
            "Epoch 139/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 140/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340727472128.0000 - accuracy: 0.1876\n",
            "Epoch 141/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.1876\n",
            "Epoch 142/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1876\n",
            "Epoch 143/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 144/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.1876\n",
            "Epoch 145/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 146/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340740055040.0000 - accuracy: 0.1876\n",
            "Epoch 147/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340765220864.0000 - accuracy: 0.1876\n",
            "Epoch 148/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 149/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340765220864.0000 - accuracy: 0.1876\n",
            "Epoch 150/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1876\n",
            "Epoch 151/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340761026560.0000 - accuracy: 0.1876\n",
            "Epoch 152/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1876\n",
            "Epoch 153/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340756832256.0000 - accuracy: 0.1876\n",
            "Epoch 154/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340773609472.0000 - accuracy: 0.1876\n",
            "Epoch 155/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.1876\n",
            "Epoch 156/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340740055040.0000 - accuracy: 0.1876\n",
            "Epoch 157/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 158/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 159/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 160/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1876\n",
            "Epoch 161/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 162/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 163/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 164/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 165/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1876\n",
            "Epoch 166/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1876\n",
            "Epoch 167/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.1876\n",
            "Epoch 168/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 169/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1876\n",
            "Epoch 170/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 171/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 172/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340769415168.0000 - accuracy: 0.1876\n",
            "Epoch 173/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 174/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1876\n",
            "Epoch 175/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.1876\n",
            "Epoch 176/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340721180672.0000 - accuracy: 0.1876\n",
            "Epoch 177/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 178/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 179/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 180/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 181/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 182/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340769415168.0000 - accuracy: 0.1876\n",
            "Epoch 183/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 184/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 185/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 186/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340767318016.0000 - accuracy: 0.1876\n",
            "Epoch 187/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 188/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340769415168.0000 - accuracy: 0.1876\n",
            "Epoch 189/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.1876\n",
            "Epoch 190/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340733763584.0000 - accuracy: 0.1876\n",
            "Epoch 191/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 192/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340773609472.0000 - accuracy: 0.1876\n",
            "Epoch 193/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1876\n",
            "Epoch 194/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1876\n",
            "Epoch 195/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340765220864.0000 - accuracy: 0.1876\n",
            "Epoch 196/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 197/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 198/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 199/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340756832256.0000 - accuracy: 0.1876\n",
            "Epoch 200/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 201/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 202/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 203/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 204/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 205/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1876\n",
            "Epoch 206/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 207/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340773609472.0000 - accuracy: 0.1876\n",
            "Epoch 208/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 209/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1876\n",
            "Epoch 210/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.1876\n",
            "Epoch 211/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340731666432.0000 - accuracy: 0.1876\n",
            "Epoch 212/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1876\n",
            "Epoch 213/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 214/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340767318016.0000 - accuracy: 0.1876\n",
            "Epoch 215/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340731666432.0000 - accuracy: 0.1876\n",
            "Epoch 216/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1876\n",
            "Epoch 217/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 218/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 219/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340761026560.0000 - accuracy: 0.1876\n",
            "Epoch 220/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 221/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340756832256.0000 - accuracy: 0.1876\n",
            "Epoch 222/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 223/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1876\n",
            "Epoch 224/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.1876\n",
            "Epoch 225/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 226/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340769415168.0000 - accuracy: 0.1876\n",
            "Epoch 227/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1876\n",
            "Epoch 228/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340769415168.0000 - accuracy: 0.1876\n",
            "Epoch 229/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 230/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1876\n",
            "Epoch 231/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1876\n",
            "Epoch 232/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 233/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340756832256.0000 - accuracy: 0.1876\n",
            "Epoch 234/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 235/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 236/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1876\n",
            "Epoch 237/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 238/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 239/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1876\n",
            "Epoch 240/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1876\n",
            "Epoch 241/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340761026560.0000 - accuracy: 0.1876\n",
            "Epoch 242/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340765220864.0000 - accuracy: 0.1876\n",
            "Epoch 243/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1876\n",
            "Epoch 244/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340765220864.0000 - accuracy: 0.1876\n",
            "Epoch 245/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.1876\n",
            "Epoch 246/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1876\n",
            "Epoch 247/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.1876\n",
            "Epoch 248/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340723277824.0000 - accuracy: 0.1876\n",
            "Epoch 249/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1876\n",
            "Epoch 250/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1876\n",
            "Epoch 251/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 252/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 253/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 254/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 255/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 256/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340771512320.0000 - accuracy: 0.1876\n",
            "Epoch 257/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340710694912.0000 - accuracy: 0.1876\n",
            "Epoch 258/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1876\n",
            "Epoch 259/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 260/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340769415168.0000 - accuracy: 0.1876\n",
            "Epoch 261/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 262/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340769415168.0000 - accuracy: 0.1876\n",
            "Epoch 263/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340727472128.0000 - accuracy: 0.1876\n",
            "Epoch 264/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.1876\n",
            "Epoch 265/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 266/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 267/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 268/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340731666432.0000 - accuracy: 0.1876\n",
            "Epoch 269/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 270/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 271/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1876\n",
            "Epoch 272/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340729569280.0000 - accuracy: 0.1876\n",
            "Epoch 273/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1876\n",
            "Epoch 274/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340756832256.0000 - accuracy: 0.1876\n",
            "Epoch 275/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 276/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 277/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340756832256.0000 - accuracy: 0.1876\n",
            "Epoch 278/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1876\n",
            "Epoch 279/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 280/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 281/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1876\n",
            "Epoch 282/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 283/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1876\n",
            "Epoch 284/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 285/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1876\n",
            "Epoch 286/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.1876\n",
            "Epoch 287/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340733763584.0000 - accuracy: 0.1876\n",
            "Epoch 288/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 289/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340779900928.0000 - accuracy: 0.1876\n",
            "Epoch 290/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 291/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 292/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 293/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340761026560.0000 - accuracy: 0.1876\n",
            "Epoch 294/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340700209152.0000 - accuracy: 0.1876\n",
            "Epoch 295/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340765220864.0000 - accuracy: 0.1876\n",
            "Epoch 296/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340756832256.0000 - accuracy: 0.1876\n",
            "Epoch 297/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340731666432.0000 - accuracy: 0.1876\n",
            "Epoch 298/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1876\n",
            "Epoch 299/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 300/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 301/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1876\n",
            "Epoch 302/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 303/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.1876\n",
            "Epoch 304/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340729569280.0000 - accuracy: 0.1876\n",
            "Epoch 305/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 306/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340756832256.0000 - accuracy: 0.1876\n",
            "Epoch 307/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340733763584.0000 - accuracy: 0.1876\n",
            "Epoch 308/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340729569280.0000 - accuracy: 0.1876\n",
            "Epoch 309/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 310/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340725374976.0000 - accuracy: 0.1876\n",
            "Epoch 311/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.1876\n",
            "Epoch 312/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 313/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 314/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 315/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340771512320.0000 - accuracy: 0.1876\n",
            "Epoch 316/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 317/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 318/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340740055040.0000 - accuracy: 0.1876\n",
            "Epoch 319/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340761026560.0000 - accuracy: 0.1876\n",
            "Epoch 320/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1876\n",
            "Epoch 321/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 322/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 323/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340731666432.0000 - accuracy: 0.1876\n",
            "Epoch 324/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340733763584.0000 - accuracy: 0.1876\n",
            "Epoch 325/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1876\n",
            "Epoch 326/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 327/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.1876\n",
            "Epoch 328/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340773609472.0000 - accuracy: 0.1876\n",
            "Epoch 329/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 330/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.1876\n",
            "Epoch 331/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.1876\n",
            "Epoch 332/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1876\n",
            "Epoch 333/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340737957888.0000 - accuracy: 0.1876\n",
            "Epoch 334/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 335/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1876\n",
            "Epoch 336/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 337/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340773609472.0000 - accuracy: 0.1876\n",
            "Epoch 338/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.1876\n",
            "Epoch 339/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.1876\n",
            "Epoch 340/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 341/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 342/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340740055040.0000 - accuracy: 0.1876\n",
            "Epoch 343/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 344/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340756832256.0000 - accuracy: 0.1876\n",
            "Epoch 345/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340725374976.0000 - accuracy: 0.1876\n",
            "Epoch 346/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1876\n",
            "Epoch 347/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1876\n",
            "Epoch 348/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 349/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.1876\n",
            "Epoch 350/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340733763584.0000 - accuracy: 0.1876\n",
            "Epoch 351/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340740055040.0000 - accuracy: 0.1876\n",
            "Epoch 352/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340773609472.0000 - accuracy: 0.1876\n",
            "Epoch 353/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 354/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340740055040.0000 - accuracy: 0.1876\n",
            "Epoch 355/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340740055040.0000 - accuracy: 0.1876\n",
            "Epoch 356/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340740055040.0000 - accuracy: 0.1876\n",
            "Epoch 357/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 358/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 359/400\n",
            "1084/1084 [==============================] - 2s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.1876\n",
            "Epoch 360/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 361/400\n",
            "1084/1084 [==============================] - 2s 1ms/step - loss: 22340769415168.0000 - accuracy: 0.1876\n",
            "Epoch 362/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1876\n",
            "Epoch 363/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 364/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 365/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 366/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 367/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340744249344.0000 - accuracy: 0.1876\n",
            "Epoch 368/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 369/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1876\n",
            "Epoch 370/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 371/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1876\n",
            "Epoch 372/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340750540800.0000 - accuracy: 0.1876\n",
            "Epoch 373/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340754735104.0000 - accuracy: 0.1876\n",
            "Epoch 374/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340731666432.0000 - accuracy: 0.1876\n",
            "Epoch 375/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.1876\n",
            "Epoch 376/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340748443648.0000 - accuracy: 0.1876\n",
            "Epoch 377/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340735860736.0000 - accuracy: 0.1876\n",
            "Epoch 378/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 379/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1876\n",
            "Epoch 380/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340758929408.0000 - accuracy: 0.1876\n",
            "Epoch 381/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340746346496.0000 - accuracy: 0.1876\n",
            "Epoch 382/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340742152192.0000 - accuracy: 0.1876\n",
            "Epoch 383/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340763123712.0000 - accuracy: 0.1876\n",
            "Epoch 384/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 385/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340752637952.0000 - accuracy: 0.1876\n",
            "Epoch 386/400\n",
            "1084/1084 [==============================] - 1s 1ms/step - loss: 22340765220864.0000 - accuracy: 0.1876\n",
            "Epoch 387/400\n",
            " 756/1084 [===================>..........] - ETA: 0s - loss: 27661302759424.0000 - accuracy: 0.1854"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c0c91916a5c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}